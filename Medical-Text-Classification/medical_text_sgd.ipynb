{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tsungmin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tsungmin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/tsungmin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/tsungmin/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as sk_stop_words\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import classification_report as cls_report\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler as ROS\n",
    "\n",
    "import re\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, sent_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_medical_data(fn, is_train=True):\n",
    "    \"\"\"Return DataFrame of medical data\n",
    "    \n",
    "    Train data columns: [label, doc]\n",
    "    Test data columns: [text]\n",
    "    \"\"\"\n",
    "    if is_train:\n",
    "        df = pd.read_table(fn, sep='\\t', names=['label', 'doc'])\n",
    "    else:\n",
    "        df = pd.read_table(fn, names=['doc'])\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def save_predict_result(fn, pred):\n",
    "    \n",
    "    df = pd.DataFrame(pred)\n",
    "    df.to_csv(fn, header=None, index=None)\n",
    "    \n",
    "def subsample_idx(n_samples, labels):\n",
    "    \n",
    "    count = (5 * np.random.rand(5) + n_samples).astype(int)\n",
    "    shuffle_idx = np.arange(len(labels))\n",
    "    sub_idx = []\n",
    "    for idx in shuffle_idx:\n",
    "        if count[label_train.values[idx] - 1] > 0:\n",
    "            sub_idx.append(idx)\n",
    "            count[label_train.values[idx] - 1] -= 1\n",
    "    \n",
    "    return np.array(sub_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using NTLK to do lemmaization \n",
    "# https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html\n",
    "\n",
    "def lemma_stem(lemmatizer, doc, stopwords):\n",
    "    doc = re.sub(r'\\d+', '', doc)\n",
    "    \n",
    "    for sent in sent_tokenize(doc):\n",
    "        \n",
    "        for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "        \n",
    "            token = token.lower() #if self.lower else token\n",
    "            token = token.strip()    #if self.strip else token\n",
    "            token = token.strip('_') #if self.strip else token\n",
    "            token = token.strip('*') #if self.strip else token\n",
    "\n",
    "            # If stopword, ignore token and continue\n",
    "            if token in stopwords or len(token) <= 2:\n",
    "                continue\n",
    "                                  \n",
    "            if all(char in string.punctuation for char in token):\n",
    "                continue\n",
    "                                  \n",
    "            lemma = lemmatize(lemmatizer, token, tag)\n",
    "            yield lemma                      \n",
    "            \n",
    "def lemmatize(lemmatizer, token, tag):\n",
    "    tag = {\n",
    "        'N': wn.NOUN,\n",
    "        'V': wn.VERB,\n",
    "        'R': wn.ADV,\n",
    "        'J': wn.ADJ\n",
    "    }.get(tag[0], wn.NOUN)\n",
    "                                  \n",
    "    return lemmatizer.lemmatize(token, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_medical_data('train.dat', True)\n",
    "\n",
    "# cls = [1, 2, 3, 4, 5]\n",
    "# for c in cls:\n",
    "#     data['is_cls{}'.format(c)] = \\\n",
    "#         np.array(data.label.values == c, dtype=np.int)\n",
    "#data['doc_sent'] = data['doc'].apply(lambda doc : doc.count('.'))\n",
    "\n",
    "cls_weight = compute_class_weight('balanced', np.unique(data.label.values), data.label.values)\n",
    "cls_weight = {k + 1: v for k, v in enumerate(cls_weight)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(sw.words('english'))\n",
    "data['lemma'] = data['doc'].apply(\n",
    "            lambda doc: ' '.join(lemma_stem(lemmatizer, doc, stop_words)))\n",
    "\n",
    "# data['lemma_count'] = \\\n",
    "#     data['lemma'].apply(lambda text: len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('tran_stemm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_medical_data('test.dat', False)\n",
    "#test['doc_sent'] = test['doc'].apply(lambda doc : doc.count('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(sw.words('english'))\n",
    "test['lemma'] = test['doc'].apply(\n",
    "            lambda doc: ' '.join(lemma_stem(lemmatizer, doc, stop_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_valid = train_test_split(data, test_size=0.2, \n",
    "                                          stratify=data.label, \n",
    "                                          random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 4))),\n",
    "    ('clf', SGDClassifier(loss='modified_huber',\n",
    "                          alpha=1e-4, \n",
    "                          l1_ratio=1e-4, penalty='elasticnet',\n",
    "                          max_iter=5000, average=True, tol=1e-4,\n",
    "                          #random_state=42,\n",
    "                          #class_weight=cls_weight #{1: 1, 2: 1, 3: 1, 4:1, 5:2}\n",
    "                         ))\n",
    "])\n",
    "\n",
    "sgd_model = sgd_model.fit(data_train.lemma, data_train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "sgd macro f1 (training): 0.8129281000366078\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.92      0.87      2530\n",
      "          2       0.79      0.74      0.76      1195\n",
      "          3       0.83      0.76      0.80      1540\n",
      "          4       0.82      0.89      0.85      2441\n",
      "          5       0.81      0.75      0.78      3844\n",
      "\n",
      "avg / total       0.82      0.82      0.82     11550\n",
      "\n",
      "[[2325   35   36   27  107]\n",
      " [  92  882   16   22  183]\n",
      " [  75   16 1171   75  203]\n",
      " [  31    8   37 2172  193]\n",
      " [ 273  178  144  352 2897]]\n",
      "================================================================================\n",
      "sgd macro f1: 0.5014083852826295\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.67      0.66       633\n",
      "          2       0.43      0.46      0.44       299\n",
      "          3       0.43      0.36      0.39       385\n",
      "          4       0.59      0.62      0.61       610\n",
      "          5       0.41      0.40      0.41       961\n",
      "\n",
      "avg / total       0.50      0.51      0.51      2888\n",
      "\n",
      "[[426  37  29  18 123]\n",
      " [ 31 137  10  16 105]\n",
      " [ 43   9 140  43 150]\n",
      " [ 19   8  26 379 178]\n",
      " [135 131 123 186 386]]\n"
     ]
    }
   ],
   "source": [
    "sgd_pred_train = sgd_model.predict(data_train.lemma)\n",
    "sgd_pred_valid = sgd_model.predict(data_valid.lemma)\n",
    "sgd_score_train = f1_score(data_train.label, sgd_pred_train, average='macro')\n",
    "sgd_score_valid = f1_score(data_valid.label, sgd_pred_valid, average='macro')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print('sgd macro f1 (training):', sgd_score_train)\n",
    "print(cls_report(data_train.label, sgd_pred_train))\n",
    "print(confusion_matrix(data_train.label, sgd_pred_train))\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "print('sgd macro f1:', sgd_score_valid)\n",
    "print(cls_report(data_valid.label, sgd_pred_valid))\n",
    "print(confusion_matrix(data_valid.label, sgd_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_full_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words, ngram_range=(1, 4))),\n",
    "    ('clf', SGDClassifier(loss='modified_huber',\n",
    "                          alpha=1e-4,\n",
    "                          l1_ratio=1e-4, penalty='elasticnet',\n",
    "                          max_iter=5000, average=True, tol=1e-4,\n",
    "                          #random_state=42,\n",
    "                          #class_weight=cls_weight #{1: 1, 2: 1, 3: 1, 4:1, 5:2}\n",
    "                         ))\n",
    "])\n",
    "\n",
    "sgd_full_model = sgd_full_model.fit(data.lemma, data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "sgd full macro f1 (training): 0.7709761277722308\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.91      0.85      3163\n",
      "          2       0.75      0.67      0.70      1494\n",
      "          3       0.78      0.73      0.75      1925\n",
      "          4       0.79      0.86      0.82      3051\n",
      "          5       0.76      0.69      0.73      4805\n",
      "\n",
      "avg / total       0.78      0.78      0.77     14438\n",
      "\n",
      "[[2868   47   56   35  157]\n",
      " [ 137  995   25   23  314]\n",
      " [ 116   20 1397  104  288]\n",
      " [  57   26   61 2633  274]\n",
      " [ 430  243  244  554 3334]]\n",
      "================================================================================\n",
      "sgd full macro f1: 0.7707513199518771\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.91      0.85       633\n",
      "          2       0.73      0.71      0.72       299\n",
      "          3       0.77      0.72      0.75       385\n",
      "          4       0.78      0.85      0.81       610\n",
      "          5       0.77      0.68      0.72       961\n",
      "\n",
      "avg / total       0.77      0.78      0.77      2888\n",
      "\n",
      "[[578  10  14  10  21]\n",
      " [ 21 212   7   3  56]\n",
      " [ 25   3 278  19  60]\n",
      " [ 10   9  12 518  61]\n",
      " [ 90  57  48 112 654]]\n"
     ]
    }
   ],
   "source": [
    "sgd_pred_train = sgd_full_model.predict(data.lemma)\n",
    "sgd_pred_valid = sgd_full_model.predict(data_valid.lemma)\n",
    "sgd_score_train = f1_score(data.label, sgd_pred_train, average='macro')\n",
    "sgd_score_valid = f1_score(data_valid.label, sgd_pred_valid, average='macro')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print('sgd full macro f1 (training):', sgd_score_train)\n",
    "print(cls_report(data.label, sgd_pred_train))\n",
    "print(confusion_matrix(data.label, sgd_pred_train))\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "print('sgd full macro f1:', sgd_score_valid)\n",
    "print(cls_report(data_valid.label, sgd_pred_valid))\n",
    "print(confusion_matrix(data_valid.label, sgd_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = sgd_full_model.predict(test.lemma)\n",
    "joblib.dump(sgd_full_model, 'sgd_full_model_v2.pkl', compress=1)\n",
    "save_predict_result('sgd_full_model_v2.dat', y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_vec = CountVectorizer(min_df=5, stop_words=stop_words, ngram_range=(1, 4))\n",
    "X_vec = imb_vec.fit_transform(data_train.lemma)\n",
    "\n",
    "# Oversampling on feature space\n",
    "smote = SMOTE()\n",
    "X_vec_imb, y_imb = smote.fit_sample(X_vec, data_train.label)\n",
    "\n",
    "# update vocabulary \n",
    "vocab = imb_vec.vocabulary_\n",
    "vocab = {'_'.join(k.split()): v for k, v in vocab.items() }\n",
    "imb_vec.vocabulary_ = vocab\n",
    "\n",
    "# convert feature back to text representation\n",
    "X_vec_imb_inv = [' '.join(x) for x in imb_vec.inverse_transform(X_vec_imb)]\n",
    "\n",
    "# Tfidf feature \n",
    "imb_tfidf = TfidfVectorizer(min_df=5, stop_words=stop_words)\n",
    "X_tfidf_imb = imb_tfidf.fit_transform(X_vec_imb_inv, y_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_model = SGDClassifier(loss='modified_huber', \n",
    "                          alpha=1e-4,\n",
    "                          l1_ratio=1e-4, penalty='elasticnet',\n",
    "                          max_iter=5000, average=True, tol=1e-4,\n",
    "                          #random_state=42,\n",
    "                          #class_weight=cls_weight #{1: 1, 2: 1, 3: 1, 4:1, 5:2}\n",
    "                         )\n",
    "\n",
    "imb_model = imb_model.fit(X_tfidf_imb, y_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "imb macro f1 (training): 0.8832197294190374\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.89      0.93      0.91      3844\n",
      "          2       0.89      0.97      0.93      3844\n",
      "          3       0.89      0.95      0.92      3844\n",
      "          4       0.88      0.93      0.91      3844\n",
      "          5       0.90      0.65      0.75      3844\n",
      "\n",
      "avg / total       0.89      0.89      0.88     19220\n",
      "\n",
      "[[3573  100   85   26   60]\n",
      " [  43 3738   15    6   42]\n",
      " [  42   21 3670   46   65]\n",
      " [  33   30   74 3593  114]\n",
      " [ 321  331  285  417 2490]]\n",
      "================================================================================\n",
      "imb macro f1: 0.5912234448187933\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       633\n",
      "          2       0.49      0.57      0.53       299\n",
      "          3       0.50      0.52      0.51       385\n",
      "          4       0.67      0.72      0.70       610\n",
      "          5       0.53      0.43      0.47       961\n",
      "\n",
      "avg / total       0.59      0.60      0.59      2888\n",
      "\n",
      "[[501  32  24  13  63]\n",
      " [ 27 171   9  15  77]\n",
      " [ 39   8 201  24 113]\n",
      " [ 15   7  37 441 110]\n",
      " [125 134 130 161 411]]\n"
     ]
    }
   ],
   "source": [
    "imb_pred_train = imb_model.predict(X_tfidf_imb)\n",
    "imb_pred_valid = imb_model.predict(imb_tfidf.transform(data_valid.lemma))\n",
    "imb_score_train = f1_score(y_imb, imb_pred_train, average='macro')\n",
    "imb_score_valid = f1_score(data_valid.label, imb_pred_valid, average='macro')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print('imb macro f1 (training):', imb_score_train)\n",
    "print(cls_report(y_imb, imb_pred_train))\n",
    "print(confusion_matrix(y_imb, imb_pred_train))\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "print('imb macro f1:', imb_score_valid)\n",
    "print(cls_report(data_valid.label, imb_pred_valid))\n",
    "print(confusion_matrix(data_valid.label, imb_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_vec = CountVectorizer(min_df=5, stop_words=stop_words, ngram_range=(1, 4))\n",
    "X_vec = imb_vec.fit_transform(data.lemma)\n",
    "\n",
    "# Oversampling on feature space\n",
    "smote = SMOTE(random_state=42)\n",
    "X_vec_imb, y_imb = smote.fit_sample(X_vec, data.label)\n",
    "\n",
    "# update vocabulary \n",
    "vocab = imb_vec.vocabulary_\n",
    "vocab = {'_'.join(k.split()): v for k, v in vocab.items() }\n",
    "imb_vec.vocabulary_ = vocab\n",
    "\n",
    "# convert feature back to text representation\n",
    "X_vec_imb_inv = [' '.join(x) for x in imb_vec.inverse_transform(X_vec_imb)]\n",
    "\n",
    "# Tfidf feature \n",
    "imb_tfidf = TfidfVectorizer(min_df=5, stop_words=stop_words)\n",
    "X_tfidf_imb = imb_tfidf.fit_transform(X_vec_imb_inv, y_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_model_full = SGDClassifier(loss='modified_huber', \n",
    "                          alpha=1e-4,\n",
    "                          l1_ratio=1e-4, penalty='elasticnet',\n",
    "                          max_iter=5000, average=True, tol=1e-4,\n",
    "                          #random_state=42,\n",
    "                          #class_weight=cls_weight #{1: 1, 2: 1, 3: 1, 4:1, 5:2}\n",
    "                         )\n",
    "\n",
    "imb_model_full = imb_model_full.fit(X_tfidf_imb, y_imb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "imb full macro f1 (training): 0.8564096031470211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.92      0.89      4805\n",
      "          2       0.86      0.96      0.91      4805\n",
      "          3       0.87      0.94      0.90      4805\n",
      "          4       0.85      0.92      0.89      4805\n",
      "          5       0.86      0.58      0.69      4805\n",
      "\n",
      "avg / total       0.86      0.86      0.86     24025\n",
      "\n",
      "[[4410  141  118   43   93]\n",
      " [  70 4636   26    9   64]\n",
      " [  76   28 4501   81  119]\n",
      " [  53   52  109 4432  159]\n",
      " [ 461  509  430  641 2764]]\n",
      "================================================================================\n",
      "imb full macro f1: 0.7104570249444975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.88      0.82       633\n",
      "          2       0.61      0.78      0.69       299\n",
      "          3       0.64      0.70      0.67       385\n",
      "          4       0.73      0.83      0.78       610\n",
      "          5       0.74      0.51      0.60       961\n",
      "\n",
      "avg / total       0.72      0.71      0.70      2888\n",
      "\n",
      "[[555  20  19   9  30]\n",
      " [ 20 233   7   9  30]\n",
      " [ 31   5 271  24  54]\n",
      " [ 11   9  28 508  54]\n",
      " [110 114  98 150 489]]\n"
     ]
    }
   ],
   "source": [
    "imb_pred_train = imb_model_full.predict(X_tfidf_imb)\n",
    "imb_pred_valid = imb_model_full.predict(imb_tfidf.transform(data_valid.lemma))\n",
    "imb_score_train = f1_score(y_imb, imb_pred_train, average='macro')\n",
    "imb_score_valid = f1_score(data_valid.label, imb_pred_valid, average='macro')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print('imb full macro f1 (training):', imb_score_train)\n",
    "print(cls_report(y_imb, imb_pred_train))\n",
    "print(confusion_matrix(y_imb, imb_pred_train))\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "print('imb full macro f1:', imb_score_valid)\n",
    "print(cls_report(data_valid.label, imb_pred_valid))\n",
    "print(confusion_matrix(data_valid.label, imb_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = imb_model_full.predict(imb_tfidf.transform(test.lemma))\n",
    "joblib.dump(imb_model_full, 'imb_model_full_v2.pkl', compress=1)\n",
    "save_predict_result('imb_model_full_v2.dat', y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "from collections import Counter\n",
    "\n",
    "def genrate_syn_len(k, true_doc_len):\n",
    "    \"\"\"Generate k samples token length\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    mu = np.mean(true_doc_len)\n",
    "    sigma = np.std(true_doc_len)\n",
    "    lower = np.min(true_doc_len)\n",
    "    upper = np.max(true_doc_len)\n",
    "    \n",
    "    X = truncnorm((lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "    \n",
    "    return X.rvs(k).astype(np.int)\n",
    "\n",
    "\n",
    "def generate_text(X, k_lens):\n",
    "    \"\"\"Generate text from sample\n",
    "    \n",
    "    X: list of docs\n",
    "    k_lens: length of k syn samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the word frequency from true sample\n",
    "    counter = Counter()\n",
    "    for x in X:\n",
    "        counter.update(x.split())\n",
    "    vocabs = list(counter.keys())\n",
    "    freqs = np.array(list(counter.values()))\n",
    "    freqs = freqs / np.sum(freqs)\n",
    "    \n",
    "    syns_text = []\n",
    "    for k_len in k_lens:\n",
    "        # sample text content based on word freq from source\n",
    "        k_text = ' '.join(np.random.choice(vocabs, k_len, p=freqs))\n",
    "        syns_text.append(k_text)\n",
    "        \n",
    "    return syns_text\n",
    "\n",
    "\n",
    "def generate_syn_text(X, y):\n",
    "    \"\"\"Generate fake sample text data\n",
    "    \n",
    "    X: list of docs\n",
    "    y: label of docs\n",
    "    \"\"\"\n",
    "    \n",
    "    # find major class count\n",
    "    cls_max_count = (np.max(np.bincount(y)))\n",
    "    \n",
    "    syn_texts = []\n",
    "    syn_labels = []\n",
    "    \n",
    "    cls = np.unique(y)\n",
    "    for c in cls:\n",
    "        cls_docs = X[y == c]\n",
    "        n_cls_docs = len(cls_docs)        \n",
    "        if n_cls_docs == cls_max_count:\n",
    "            continue\n",
    "        \n",
    "        # compute class token distribution\n",
    "        doc_lens =  np.apply_along_axis(lambda x : len(x[0].split()), 1, cls_docs.reshape(-1, 1))\n",
    "        #doc_sort_idx = np.argsort(doc_lens)\n",
    "        #cls_docs = cls_docs[doc_sort_idx]\n",
    "        \n",
    "        # generate k sample\n",
    "        k = cls_max_count - len(cls_docs)\n",
    "        k_lens = genrate_syn_len(k, doc_lens)\n",
    "        k_lens = np.sort(k_lens)\n",
    "        batch_size = 16\n",
    "        n_batch = k // batch_size \n",
    "        n_batch = (n_batch + 1) if (k % n_batch) != 0 else n_batch\n",
    "        \n",
    "        # generate data with same length source\n",
    "        for b_idx in range(n_batch):\n",
    "            batch_sidx = (b_idx) * batch_size\n",
    "            batch_eidx = (b_idx + 1) * batch_size\n",
    "            if batch_eidx >= k:\n",
    "                k_len_batch = k_lens[batch_sidx:]\n",
    "            else:\n",
    "                k_len_batch = k_lens[batch_sidx:batch_eidx]\n",
    "            \n",
    "            k_len_med = np.median(k_len_batch) if len(k_len_batch) >= 3 else np.mean(k_len_batch)\n",
    "            k_len_med = int(k_len_med)\n",
    "            \n",
    "            X_batch = None\n",
    "            range_relax = 1\n",
    "            while X_batch is None or len(X_batch) <= batch_size:\n",
    "                lower = doc_lens >= (k_len_med - range_relax)\n",
    "                upper = doc_lens <= (k_len_med + range_relax)\n",
    "                X_batch = cls_docs[lower & upper]\n",
    "                range_relax += 1\n",
    "            \n",
    "            syn_batch_texts = generate_text(X_batch, k_len_batch)\n",
    "            syn_texts.extend(syn_batch_texts)\n",
    "            \n",
    "        syn_labels.extend([c] * k)\n",
    "        \n",
    "    return np.array(syn_texts), np.array(syn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_vec = CountVectorizer(min_df=5, stop_words=stop_words, ngram_range=(1, 4))\n",
    "X_vec_syn = syn_vec.fit_transform(data_train.lemma)\n",
    "\n",
    "# update vocabulary \n",
    "vocab = syn_vec.vocabulary_\n",
    "vocab = {'_'.join(k.split()): v for k, v in vocab.items() }\n",
    "syn_vec.vocabulary_ = vocab\n",
    "\n",
    "# convert feature back to text representation\n",
    "X_vec_syn_inv = [' '.join(x) for x in syn_vec.inverse_transform(X_vec_syn)]\n",
    "\n",
    "X_train = np.array(X_vec_syn_inv)\n",
    "#X_train = data_train.lemma.values\n",
    "y_train = data_train.label.values\n",
    "\n",
    "syn_texts, syn_labels = generate_syn_text(X_train, y_train)\n",
    "X_train_syn = np.hstack([X_train, syn_texts])\n",
    "y_train_syn = np.hstack([y_train, syn_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df=5, stop_words=stop_words)),\n",
    "    ('clf', SGDClassifier(loss='modified_huber', \n",
    "                          alpha=1e-4,\n",
    "                          l1_ratio=1e-4, penalty='elasticnet',\n",
    "                          max_iter=5000, average=True, tol=1e-4,\n",
    "                          #random_state=42,\n",
    "                          #class_weight=cls_weight #{1: 1, 2: 1, 3: 1, 4:1, 5:2}\n",
    "                         ))\n",
    "])\n",
    "\n",
    "syn_model = syn_model.fit(X_train_syn, y_train_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "syn macro f1 (training): 0.8809035365608768\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.89      0.93      0.91      3844\n",
      "          2       0.88      0.98      0.93      3844\n",
      "          3       0.88      0.96      0.92      3844\n",
      "          4       0.87      0.94      0.91      3844\n",
      "          5       0.92      0.62      0.74      3844\n",
      "\n",
      "avg / total       0.89      0.89      0.88     19220\n",
      "\n",
      "[[3586   96   76   26   60]\n",
      " [  39 3769   14   10   12]\n",
      " [  50   23 3675   56   40]\n",
      " [  33   28   67 3608  108]\n",
      " [ 326  369  321  428 2400]]\n",
      "================================================================================\n",
      "syn macro f1: 0.5966456802627192\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       633\n",
      "          2       0.49      0.64      0.56       299\n",
      "          3       0.49      0.56      0.52       385\n",
      "          4       0.67      0.72      0.69       610\n",
      "          5       0.55      0.40      0.46       961\n",
      "\n",
      "avg / total       0.60      0.60      0.59      2888\n",
      "\n",
      "[[504  33  27  11  58]\n",
      " [ 27 191   9  17  55]\n",
      " [ 39   9 216  29  92]\n",
      " [ 13  12  37 438 110]\n",
      " [127 143 150 160 381]]\n"
     ]
    }
   ],
   "source": [
    "syn_pred_train = syn_model.predict(X_train_syn)\n",
    "syn_pred_valid = syn_model.predict(data_valid.lemma)\n",
    "syn_score_train = f1_score(y_train_syn, syn_pred_train, average='macro')\n",
    "syn_score_valid = f1_score(data_valid.label, syn_pred_valid, average='macro')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print('syn macro f1 (training):', syn_score_train)\n",
    "print(cls_report(y_train_syn, syn_pred_train))\n",
    "print(confusion_matrix(y_train_syn, syn_pred_train))\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "print('syn macro f1:', syn_score_valid)\n",
    "print(cls_report(data_valid.label, syn_pred_valid))\n",
    "print(confusion_matrix(data_valid.label, syn_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_vec = CountVectorizer(min_df=5, stop_words=stop_words, ngram_range=(1, 4))\n",
    "X_vec_syn = syn_vec.fit_transform(data.lemma)\n",
    "\n",
    "# update vocabulary \n",
    "vocab = syn_vec.vocabulary_\n",
    "vocab = {'_'.join(k.split()): v for k, v in vocab.items() }\n",
    "syn_vec.vocabulary_ = vocab\n",
    "\n",
    "# convert feature back to text representation\n",
    "X_vec_syn_inv = [' '.join(x) for x in syn_vec.inverse_transform(X_vec_syn)]\n",
    "\n",
    "X_train = np.array(X_vec_syn_inv)\n",
    "#X_train = data.lemma.values\n",
    "y_train = data.label.values\n",
    "\n",
    "syn_texts, syn_labels = generate_syn_text(X_train, y_train)\n",
    "X_train_syn = np.hstack([X_train, syn_texts])\n",
    "y_train_syn = np.hstack([y_train, syn_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_full_model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(min_df=5, stop_words=stop_words)),\n",
    "    ('clf', SGDClassifier(loss='modified_huber', \n",
    "                          alpha=1e-4,\n",
    "                          l1_ratio=1e-4, penalty='elasticnet',\n",
    "                          max_iter=5000, average=True, tol=1e-4,\n",
    "                          #random_state=42,\n",
    "                          #class_weight=cls_weight #{1: 1, 2: 1, 3: 1, 4:1, 5:2}\n",
    "                         ))\n",
    "])\n",
    "\n",
    "syn_full_model = syn_full_model.fit(X_train_syn, y_train_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "syn full macro f1 (training): 0.854061843992743\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.92      0.90      4805\n",
      "          2       0.86      0.97      0.91      4805\n",
      "          3       0.86      0.95      0.90      4805\n",
      "          4       0.85      0.93      0.89      4805\n",
      "          5       0.90      0.54      0.68      4805\n",
      "\n",
      "avg / total       0.87      0.86      0.85     24025\n",
      "\n",
      "[[4443  130  111   44   77]\n",
      " [  74 4673   25   13   20]\n",
      " [  78   31 4557   82   57]\n",
      " [  50   53  111 4462  129]\n",
      " [ 472  559  501  674 2599]]\n",
      "================================================================================\n",
      "syn full macro f1: 0.7134337314628192\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.87      0.82       633\n",
      "          2       0.58      0.82      0.68       299\n",
      "          3       0.64      0.77      0.70       385\n",
      "          4       0.73      0.83      0.78       610\n",
      "          5       0.78      0.48      0.59       961\n",
      "\n",
      "avg / total       0.73      0.71      0.70      2888\n",
      "\n",
      "[[553  25  19  10  26]\n",
      " [ 19 245   6   8  21]\n",
      " [ 28   6 297  20  34]\n",
      " [ 10  14  29 508  49]\n",
      " [104 136 114 148 459]]\n"
     ]
    }
   ],
   "source": [
    "syn_pred_train = syn_full_model.predict(X_train_syn)\n",
    "syn_pred_valid = syn_full_model.predict(data_valid.lemma)\n",
    "syn_score_train = f1_score(y_train_syn, syn_pred_train, average='macro')\n",
    "syn_score_valid = f1_score(data_valid.label, syn_pred_valid, average='macro')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print('syn full macro f1 (training):', syn_score_train)\n",
    "print(cls_report(y_train_syn, syn_pred_train))\n",
    "print(confusion_matrix(y_train_syn, syn_pred_train))\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "print('syn full macro f1:', syn_score_valid)\n",
    "print(cls_report(data_valid.label, syn_pred_valid))\n",
    "print(confusion_matrix(data_valid.label, syn_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = syn_full_model.predict(test.lemma)\n",
    "joblib.dump(syn_full_model, 'syn_full_model_v2.pkl', compress=1)\n",
    "save_predict_result('syn_full_model_v2.dat', y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
